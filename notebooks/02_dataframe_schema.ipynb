{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#1f77b4\">**Data Analytics 02 - DataFrame Schema**</span>\n\nThis notebook shapes raw CSV data into clean, typed DataFrames and summary views.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading CSV files into the databricks file system (dbfs)**</span>\n\nCreate a working folder in DBFS and download the raw CSV files.\n\n- `%sh` runs shell commands in the notebook context.\n- `wget` downloads the CSV files into DBFS.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DBFS folder and download sample CSVs\n",
    "%sh\n",
    "rm -r /dbfs/spark_lab\n",
    "mkdir /dbfs/spark_lab\n",
    "wget -O /dbfs/spark_lab/2019.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2019_edited.csv\n",
    "wget -O /dbfs/spark_lab/2020.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2020_edited.csv\n",
    "wget -O /dbfs/spark_lab/2021.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2021_edited.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading the CSV files into a dataframe**</span>\n\nRead the CSVs into a Spark DataFrame and preview the rows.\n\n- `spark.read.load` reads files into a DataFrame.\n- `display` shows a sample in Databricks.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load all CSVs into a Spark DataFrame\n",
    "df = spark.read.load('spark_lab/*.csv', format='csv')\n",
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Defining Schema for the dataframe**</span>\n\nApply an explicit schema so dates, numbers, and strings parse consistently.\n\n- `StructType` defines the full schema structure.\n- `StructField` defines each column name, type, and nullability.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define an explicit schema for consistent types\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "orderSchema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"CustomerName\", StringType()),\n",
    "    StructField(\"Email\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"Tax\", FloatType())\n",
    "])\n",
    "df = spark.read.load('/spark_lab/*.csv', format='csv', schema=orderSchema)\n",
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Cleaning the Data**</span>\n\nRemove duplicates and recompute tax for consistency.\n\n- `dropDuplicates` removes repeated rows.\n- `withColumn` and `col` derive and cast columns.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df = df.dropDuplicates()\n",
    "df = df.withColumn('Tax', col('UnitPrice') * 0.08)\n",
    "df = df.withColumn('Tax', col('Tax').cast(\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Creating a new Dataframe**</span>\n\nBuild a customer-focused DataFrame with parsed names.\n\n- `select` picks relevant columns.\n- `split(...).getItem(...)` extracts first and last names.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "customers_df = df.select(\"CustomerName\", \"Email\", \"Item\", \"Quantity\")\n",
    "customers_df = customers_df.withColumn(\"FirstName\", split(customers_df[\"CustomerName\"], \" \").getItem(0))\n",
    "customers_df = customers_df.withColumn(\"LastName\", split(customers_df[\"CustomerName\"], \" \").getItem(1))\n",
    "\n",
    "display(customers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Counting distinct customer entries**</span>\n\nCompare total rows to distinct rows to assess duplicates.\n\n- `count` returns row counts.\n- `distinct` removes duplicates before counting.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(customers_df.count())\n",
    "print(customers_df.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Creating a Product Sales Dataframe**</span>\n\nAggregate quantity sold by product.\n\n- `groupBy` defines the grouping key.\n- `sum` computes totals per product.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "productSales = df.select(\"Item\", \"Quantity\").groupBy(\"Item\").sum()\n",
    "display(productSales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Aggregating Yealy Sales**</span>\n\nSummarize sales counts by year.\n\n- `year` extracts the year from dates.\n- `groupBy` and `orderBy` build a yearly summary.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "yearlySales = df.select(year(\"OrderDate\").alias(\"Year\")).groupBy(\"Year\").count().orderBy(\"Year\")\n",
    "display(yearlySales)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}