{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#1f77b4\">**Data Analytics 01 - Data Ingest**</span>\n",
    "\n",
    "This notebook pulls sample sales data into DBFS, loads it into Spark, and walks through a basic SQL-driven analysis with quick visual checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading csv dataset into the databricks file system (dbfs)**</span>\n\nCreate a working folder in DBFS and download the raw CSV files.\n\n- `%sh` runs shell commands in the notebook context.\n- `wget` fetches the CSV files from GitHub into DBFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DBFS folder and download sample CSVs\n",
    "%sh\n",
    "rm -r /dbfs/spark_lab\n",
    "mkdir /dbfs/spark_lab\n",
    "wget -O /dbfs/spark_lab/2019.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2019.csv\n",
    "wget -O /dbfs/spark_lab/2020.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2020.csv\n",
    "wget -O /dbfs/spark_lab/2021.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/2021.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading csv files into a dataframe**</span>\n\nRead the CSVs into a Spark DataFrame and preview the rows.\n\n- `spark.read.load` reads files into a DataFrame.\n- `display` renders a quick preview in Databricks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load all CSVs into a Spark DataFrame\n",
    "df = spark.read.load('spark_lab/*.csv', format='csv')\n",
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Defining Schema for the dataframe**</span>\n\nApply an explicit schema so dates, numbers, and strings parse consistently.\n\n- `StructType` defines the full schema structure.\n- `StructField` defines each column name, type, and nullability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define an explicit schema for consistent types\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "orderSchema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"CustomerName\", StringType()),\n",
    "    StructField(\"Email\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"Tax\", FloatType())\n",
    "])\n",
    "df = spark.read.load('/spark_lab/*.csv', format='csv', schema=orderSchema)\n",
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Query Data using Spark SQL**</span>\n\nRegister a temp view and run SQL to explore and aggregate the data.\n\n- `createOrReplaceTempView` exposes the DataFrame as a SQL view.\n- `spark.sql` runs SQL over Spark data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Register a temp view and query with Spark SQL\n",
    "df.createOrReplaceTempView(\"salesorders\")\n",
    "spark_df = spark.sql(\"SELECT * FROM salesorders\")\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate gross revenue by year\n",
    "sqlQuery = \"SELECT CAST(YEAR(OrderDate) AS CHAR(4)) AS OrderYear, \\\n",
    "               SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue \\\n",
    "        FROM salesorders \\\n",
    "        GROUP BY CAST(YEAR(OrderDate) AS CHAR(4)) \\\n",
    "        ORDER BY OrderYear\"\n",
    "df_spark = spark.sql(sqlQuery)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Using Matplotlib for visualisation**</span>\n\nConvert to Pandas and plot revenue by year for a quick sanity check.\n\n- `toPandas` collects results to the driver for plotting.\n- `plt.bar` creates the bar chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas for local plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# matplotlib requires a Pandas dataframe, not a Spark one\n",
    "df_sales = df_spark.toPandas()\n",
    "# Create a bar plot of revenue by year\n",
    "plt.bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'])\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Using Seaborn Library**</span>\n\nRecreate the chart with Seaborn for a cleaner, styled visual.\n\n- `sns.barplot` builds a categorical bar chart with styling.\n- `plt.show` renders the chart output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use Seaborn for a styled bar chart\n",
    "import seaborn as sns\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "# Create a bar chart\n",
    "ax = sns.barplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}