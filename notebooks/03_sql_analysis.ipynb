{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#1f77b4\">**Data Analytics 03 - SQL Analysis**</span>\n\nThis notebook loads product data into Delta Lake, performs updates, and registers a managed table.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading CSV file into dbfs (Databricks File System)**</span>\n\nCreate a DBFS folder and download the product CSV.\n\n- `%sh` runs shell commands in the notebook context.\n- `wget` downloads the CSV into DBFS.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DBFS folder and download sample CSVs\n",
    "%sh\n",
    "rm -r /dbfs/delta_lab\n",
    "mkdir /dbfs/delta_lab\n",
    "wget -O /dbfs/delta_lab/products.csv https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Data-Analytics/refs/heads/main/data/products.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Loading data into a dataframe**</span>\n\nRead the CSV into a Spark DataFrame with headers.\n\n- `spark.read.load` reads the CSV file.\n- `header=True` uses the first row as column names.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load all CSVs into a Spark DataFrame\n",
    "df = spark.read.load('/delta_lab/products.csv', format='csv', header=True)\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Load the data into a delta table**</span>\n\nWrite the DataFrame to Delta format on DBFS.\n\n- `write.format(\"delta\")` selects Delta Lake.\n- `save` writes the table to the path.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#1f77b4\">**Storing in DBFS (Databricks File System)**</span>\n\nDefine the Delta table storage path in DBFS.\n\n- `delta_table_path` is the location used by Delta.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delta_table_path = \"/delta/products-delta\" \n",
    "df.write.format(\"delta\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Manipulating the Delta Table by creating a DeltaTable Object**</span>\n\nCreate a DeltaTable object and apply an update.\n\n- `DeltaTable.forPath` opens the Delta table.\n- `update` modifies records in place.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a deltaTable object\n",
    "deltaTable = DeltaTable.forPath(spark, delta_table_path)\n",
    "# Update the table (reduce price of product 771 by 10%)\n",
    "deltaTable.update(\n",
    "   condition = \"ProductID == 771\",\n",
    "   set = { \"ListPrice\": \"ListPrice * 0.9\" })\n",
    "# View the updated data as a dataframe\n",
    "deltaTable.toDF().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Creating a dataframe from the delta dataset**</span>\n\nRead the Delta table back into a DataFrame.\n\n- `spark.read.format(\"delta\").load` loads Delta data.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "new_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Explore Logging for the delta table**</span>\n\nInspect Delta transaction history for auditing.\n\n- `history` shows recent operations.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "deltaTable.history(10).show(10, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Creating a Data Catalog Table**</span>\n\nCreate a managed table in the metastore.\n\n- `saveAsTable` registers the table in the catalog.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").saveAsTable(\"default.ProductsManaged\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1f77b4\">**Accessing the Data Catalog Table**</span>\n\nQuery the managed table with SQL.\n\n- `%sql` runs SQL in a notebook cell.\n- `SELECT` reads from the catalog table.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE default;\n",
    "SELECT * FROM ProductsManaged;"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}